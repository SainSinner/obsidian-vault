База знаний Алексея Голобурдина [alexey-goloburdin/knowledge-base](https://github.com/alexey-goloburdin/knowledge-base/tree/main)
# Сравнение Greenplum и ClickHouse
[Что такое СУБД Greenplum? Задачи и особенности MPP-СУБД Greenplum](https://www.qlever.ru/press/dwh-greenplum)
# Виды таблиц
[Обзор типов таблиц | ADB Arenadata Docs](https://docs.arenadata.io/ru/ADB/current/concept/data-model/tables/table-types.html)
[Цикл статей о Greenplum. Часть 2. Оптимальный DDL / Хабр](https://habr.com/ru/companies/axenix/articles/832126/)
OLTP (англ. Online Transaction Processing), транзакционная система — обработка транзакций в реальном времени.
Онлайн-аналитическая обработка (OLAP) — это **программная технология, которую можно использовать для анализа бизнес-данных с разных точек зрения**.

**heap-таблицы**, так как они представляют из себя стандартную физическую структуру из Postgres: на каждом сегменте Greenplum записи таблицы складываются последовательно в один файл.

Этот вид таблиц выбирается, если таблица небольшая и в будущем придется много работать с данными (удалять и/или изменять). К примеру, это предпочтительный выбор для таблиц-словарей.

Для создания heap-таблицы необходимо в DDL прописать параметр _APPENDONLY_ равный _false_. Например:

```
сreate table t1 (  col1 integer,  col2 varchar(100) ) with (APPENDONLY=false) distributed by (col1);
```

В примере вы видите строку _distributed by (col1)_. Таким образом мы задаём дистрибьюцию, о которой поговорим позже.

**Append-optimized tables (AOT)** – таблицы со специальной структурой, обладающие рядом особых возможностей. Например, для этого вида таблиц доступна любая ориентация данных, а также все виды компрессии. Данный тип таблиц использует меньше ресурсов, по ним быстрее проходит сбор статистики.


# Ключи, какие бывают и для чего используются
[PostgreSQL : Документация: 9.5: 5.3. Ограничения : Компания Postgres Professional](https://postgrespro.ru/docs/postgresql/9.5/ddl-constraints)
### Первичный ключ или primary key

Первичный ключ — особенное поле в SQL-таблице, которое позволяет однозначно идентифицировать каждую запись в ней. Как правило, эти поля используются для хранения уникальных идентификаторов объектов, которые перечислены в таблице, например, это может быть ID клиента или товара.  
Первичный ключ имеет несколько свойств:

- каждая запись в таком поле должна быть уникальной;
- запись в поле не должна быть пустой;
- в одной таблице может быть только один ключ (существуют также составные ключи, которые могут включать в себя несколько полей, однако в этой статье мы не будем их рассматривать).

Ограничение первичного ключа означает, что образующий его столбец или группа столбцов может быть уникальным идентификатором строк в таблице. Для этого требуется, чтобы значения были одновременно уникальными и отличными от NULL. Таким образом, таблицы со следующими двумя определениями будут принимать одинаковые данные:

```sql
CREATE TABLE products (
    product_no integer UNIQUE NOT NULL,
    name text,
    price numeric
);

CREATE TABLE products (
    product_no integer PRIMARY KEY,
    name text,
    price numeric
);
```

Первичные ключи могут включать несколько столбцов; синтаксис похож на запись ограничений уникальности:

```sql
CREATE TABLE example (
    a integer,
    b integer,
    c integer,
    PRIMARY KEY (a, c)
);
```
### Внешний ключ или foreign key

Внешний ключ нужен для того, чтобы связать две разные SQL-таблицы между собой. Внешний ключ таблицы должен соответствует значению первичного ключа таблицы, с которой он связан. Это помогает сохранять согласованность базы данных путем обеспечения так называемой «ссылочной целостности» (referential integrity).

Ограничение внешнего ключа указывает, что значения столбца (или группы столбцов) должны соответствовать значениям в некоторой строке другой таблицы. Это называется _ссылочной целостностью_ двух связанных таблиц.

Пусть у вас уже есть таблица продуктов, которую мы неоднократно использовали ранее:

```sql
CREATE TABLE products (
    product_no integer PRIMARY KEY,
    name text,
    price numeric
);
```
Давайте предположим, что у вас есть таблица с заказами этих продуктов. Мы хотим, чтобы в таблице заказов содержались только заказы действительно существующих продуктов. Поэтому мы определим в ней ограничение внешнего ключа, ссылающееся на таблицу продуктов:

```sql
CREATE TABLE orders (
    order_id integer PRIMARY KEY,
    product_no integer REFERENCES products (product_no),
    quantity integer
);
```

С таким ограничением создать заказ со значением `product_no`, отсутствующим в таблице products (и не равным NULL), будет невозможно.

В такой схеме таблицу orders называют _подчинённой_ таблицей, а products — _главной_. Соответственно, столбцы называют так же подчинённым и главным (или ссылающимся и целевым).

Предыдущую команду можно сократить так:

```sql
CREATE TABLE orders (
    order_id integer PRIMARY KEY,
    product_no integer REFERENCES products,
    quantity integer
);
```

Внешний ключ также может ссылаться на группу столбцов. В этом случае его нужно записать в виде обычного ограничения таблицы. Например:

```sql
CREATE TABLE t1 (
  a integer PRIMARY KEY,
  b integer,
  c integer,
  FOREIGN KEY (b, c) REFERENCES other_table (c1, c2)
);
```
Естественно, число и типы столбцов в ограничении должны соответствовать числу и типам целевых столбцов.
### Уникальный ключ (Unique Key)

Гарантирует уникальность значений в столбце (или группе столбцов). Ограничения уникальности гарантируют, что данные в определённом столбце или группе столбцов уникальны среди всех строк таблицы.

Ограничения уникальности гарантируют, что данные в определённом столбце или группе столбцов уникальны среди всех строк таблицы. Ограничение записывается так:

```sql
CREATE TABLE products (
    product_no integer UNIQUE,
    name text,
    price numeric
);
```

в виде ограничения столбца и так:

```sql
CREATE TABLE products (
    product_no integer,
    name text,
    price numeric,
    UNIQUE (product_no)
);
```

в виде ограничения таблицы.

Чтобы определить ограничение уникальности для группы столбцов, запишите его в виде ограничения таблицы, перечислив имена столбцов через запятую:

```sql
CREATE TABLE example (
    a integer,
    b integer,
    c integer,
    UNIQUE (a, c)
);
```

Такое ограничение указывает, что сочетание значений перечисленных столбцов должно быть уникально во всей таблице, тогда как значения каждого столбца по отдельности не должны быть (и обычно не будут) уникальными.

Вы можете назначить уникальному ограничению имя обычным образом:

```sql
CREATE TABLE products (
    product_no integer CONSTRAINT must_be_different UNIQUE,
    name text,
    price numeric
);
```

### Составной ключ (Composite Key)

- **Назначение**: Используется, когда уникальность строки определяется комбинацией нескольких столбцов.

```sql
CREATE TABLE orders (
    order_id INT,
    product_id INT,
    quantity INT,
    PRIMARY KEY (order_id, product_id)
);
```


[Распределение данных (distribution): политики, рекомендации | ADB Arenadata Docs](https://docs.arenadata.io/ru/ADB/current/concept/data-model/tables/distribution.html)

# Переназначение ключа распределения для таблицы

В Greenplum переназначение ключа распределения (distribution key) для таблицы — это операция, которая изменяет способ распределения данных таблицы по сегментам кластера. Это может быть полезно, если текущий ключ распределения неэффективен (например, приводит к неравномерному распределению данных или к избыточному перемещению данных при выполнении JOIN).

Однако важно помнить, что изменение ключа распределения требует перераспределения данных, что может быть ресурсоемкой операцией, особенно для больших таблиц.

---

### Как переназначить ключ распределения

#### 1. **Создание новой таблицы с новым ключом распределения**

Самый простой и безопасный способ — создать новую таблицу с нужным ключом распределения и скопировать в нее данные из старой таблицы.

sql

Copy

-- Создаем новую таблицу с новым ключом распределения
CREATE TABLE new_table (
    column1 INT,
    column2 TEXT,
    column3 DATE
) DISTRIBUTED BY (column1);  -- Новый ключ распределения

-- Копируем данные из старой таблицы в новую
INSERT INTO new_table SELECT * FROM old_table;

-- Переименовываем таблицы
ALTER TABLE old_table RENAME TO old_table_backup;
ALTER TABLE new_table RENAME TO old_table;

-- Удаляем старую таблицу (если больше не нужна)
DROP TABLE old_table_backup;

Этот метод позволяет избежать блокировок и минимизировать риски.

---

#### 2. **Использование `ALTER TABLE` для изменения ключа распределения**

В Greenplum можно использовать команду `ALTER TABLE` для изменения ключа распределения, но это приведет к перераспределению данных, что может занять значительное время.

sql

Copy

ALTER TABLE table_name SET DISTRIBUTED BY (new_distribution_key);

Пример:

sql

Copy

ALTER TABLE sales SET DISTRIBUTED BY (customer_id);

**Важно:**

- Эта операция требует перераспределения данных, что может быть дорогостоящим для больших таблиц.
    
- Во время выполнения операции таблица может быть заблокирована.
    

---

#### 3. **Использование утилиты `gpreload`**

Greenplum предоставляет утилиту `gpreload`, которая позволяет изменять ключ распределения таблицы без необходимости создавать новую таблицу вручную. Эта утилита автоматически создает новую таблицу с новым ключом распределения, копирует данные и заменяет старую таблицу.

Пример использования:

bash

Copy

gpreload -d database_name -t schema_name.table_name --new-distribution-key="new_key_column"

**Преимущества:**

- Автоматизация процесса.
    
- Минимизация ручной работы.
    

---

### Когда нужно переназначать ключ распределения?

1. **Неравномерное распределение данных (skew)**:
    
    - Если данные распределены неравномерно по сегментам, это может привести к перегрузке некоторых узлов и снижению производительности.
        
2. **Неэффективные JOIN**:
    
    - Если текущий ключ распределения не совпадает с ключом JOIN, это может привести к перемещению данных (broadcast или redistribute), что замедляет выполнение запросов.
        
3. **Изменение логики использования таблицы**:
    
    - Если изменились требования к запросам или данные стали использоваться по-другому, может потребоваться изменить ключ распределения.
# Партиционирование, группирование

[Партицирование (секционирование) баз данных: что это, виды и особенности | ADB Arenadata Docs](https://docs.arenadata.io/ru/ADB/current/concept/data-model/tables/partitioning.html)
**Партиционирование (partitioning)** — это способ повышения производительности запросов за счет логического разбиения больших таблиц (например, таблиц фактов) на небольшие части, называемые **партициями (partitions)**. Партиционирование позволяет оптимизаторам запросов сканировать ограниченное число строк в таблице (на основе условий предикатов) вместо чтения всего содержимого таблицы.

# Оптимизация запросов

[База по оптимизации PostgreSQL: схема, индексы, чтение EXPLAIN, методы доступа и соединения, тюнинг](https://www.youtube.com/watch?v=gA3A_epB3So&t=2522s)
[alexey-goloburdin/knowledge-base](https://github.com/alexey-goloburdin/knowledge-base/tree/main)

**Что выдаёт EXPLAIN?**
```
Seq Scan on employee (cost=0.00..173528.84 rows=9999884 width=28) (actual time=1.248..887.986 rows=10000000 loops=1) Planning Time: 2.139 ms
Execution Time: 1143.016 ms
```
• Seq Scan - последовательное сканирование таблицы species
• cost - оценка стоимости этого узла (узлов может быть несколько)
• 0.00 - стоимость вывода первой строки этим узлом (подготовительная
работа до первой строки)
• 173528.84 — стоимость вывода всех строк этим узлом
• rows - строк в этом узле

`(cost=0.00..173528.84 rows=9999884 width=28)` - это планирование перед запросом
`(actual time=1.248..887.986 rows=10000000 loops=1)` - это результат работы

**==Чем меньше Cost тем более эффективен запрос.
==**
Cost складывается из (input/output операции (чтение/запись на диск) + использование ресурсов процессора)


**Откуда берётся стоимость?**
```sql
select
relpages, — количество страниц таблицы (её оценка в статистике) current_setting('seq_page_cost'), стоимость чтения одной страницы
relpages * current_setting('seq_page_cost')::int as total -- итог
from pg_class where relname='employee';
|relpages|current_setting|total|
|73 530  | 1             |73 530|
```
Это оценка 10-операций. Надо считать 73530 страниц с диска. Стоимость считывания одной страницы равна 1

```sql
select
reltuples, — количество строк
current_setting('cpu_tuple_cost'), — стоимость обработки одной строки reltuples * current_setting('cpu_tuple_cost')::float as total -- итог
from pg_class' where relname='employee';
reltuples|current_setting|total
|9 999 884| 0.01         |99 998,84
```
Это оценка стоимости ресурсов процессора
```
-- Сложив сложность чтения страниц диском и сложность чтения строк процессором, получили то что было в explain analyze
73 530 + 99 998,84 = 173528.84
```

**Индексное сканирование**
```sql
explain analyze select * from employee where employee_id=2;
Index Scan using employee_pkey on employee (cost=0.43..8.45 rows=1 width=28) (actual time=2.077..2.080 rows=1 loops=1) Index Cond: (employee_id = 2)
Planning Time: 0.182 ms
Execution Time: 2.108 ms
```
По колонке employee_id есть индекс (это первичный ключ), и, раз нам нужны не
все строки таблицы, а только одна строка, то эффективно достать её, используя индекс

==**Всегда ли используется индекс у столбца?**==
Нет. Индекс используется только при высокой селективности. Т.е. если нужно много данных прочитать и вывести, индекс не поможет. ==Индекс - только для запросов с высокой селективностью.==

Сканирование только индекса позволяет не считывать всю таблицу, но только при условии, что все поля под select есть в самом индексе.
```sql
create index ... include (...); -- включаем доп столбцы, поиск по ним рабоать не будет, но достать их будет можно
```

**Методы доступа к данным:**
достаём малый % строк — Index Scan
• побольше — Bitmap Index Scan
• ещё больше —- уже Seq Scan

**Способы соединения таблиц**
• nested lоор, вложенные циклы
• hash join, соединение хешированием
• merge join, соединение слиянием

**Как играться с методами доступа и способами соединения таблиц?**
(в большинстве случаев не поможет)
==Их можно временно отключать и смотреть, как это влияет на запрос:==
set enable_seqscan = off;
set enable_indexscan = off;
set enable_bitmapscan = off; 
set enable_indexonlyscan = off;
set enable_nestloop = off;
set enable_hashjoin = off;
set enable_mergejoin = off;


**Теперь ты можешь читать EXPLAIN!**
```sql
explain analyze
select e.first_name, e.last_name, ec.phone from employee e
join employee_contact ec using (employee_id);
```
```
Hash Join (cost-366886.39..781776.27 rows=9999990 width=35) (actual time-2387.383..7769.182 rows=100eeeee loops=1) Hash Cond: (ec.employee_id = e.employee_id)
→ Seq Scan on employee_contact ec (cost-0.00..203892.90 rows=9999998 width=23) (actual time-89.440..1960.488 rows=10000000 loops=1) →→Hash (cost-173528.84..173528.84 rows=9999884 width=28) (actual time=2295.571..2295.574 rows=10000000 loops=1) Buckets: 131072 Batches: 128 Memory Usage: 5925kB
→Seq Scan on employee e (cost-0.00..173528.84 rows=9999884 width=28) (actual time=0.016..999.143 rows=1000eeee loops=1)
Planning Time: 10.470 ms
JIT:
Functions: 10
Options: Inlining true, Optimization true, Expressions true, Deforming true
Timing: Generation 0.302 ms, Inlining 36.612 ms, Optimization 25.924 ms, Emission 26.924 ms, Total 89.762 ms Execution Time: 8131.726 ms
```
![[Pasted image 20250219002458.png]]

**На что обращать внимание?**
• Seq Scan большой таблицы не может быть быстрым - очевидно
• стоит использовать explain (analyze, buffers), чтобы смотреть, сколько буферов считывается на каждом узле
• стоит смотреть на большие отличия в rows и actual rows - это говорит о неверной статистике
• стоит «думать как СУБД» - насколько план оптимален и почему он такой?

```sql
explain (analyze buffers)
```
**Статистика важна.**
- Оптимизатор в плане учитывает планируемое количество строк на каждом узле
- Статистику нужно обновлять
- Можно уточнять стат `через default_statistics_target`
```sql
VACUUM ANALYZE -- ПРИНУДИТЕЛЬНЫЙ ЗАПУСК ОБНОВЛЯЕТ СТАТИСТИКУ
```


**Более умные индексы**
• составные индексы по нескольким колонкам
• покрывающие индексы для Index Only Scan
• индексы по функции например, индекс по date_trunc(some_date_field)
==тогда индекс может использоваться в запросе where date_trunc(some_date_field)=...==
• частичные индексы
строится на части таблицы, например, для строк, которые хранят почти уникальное в таблице значение по нужной колонке

**Короткие и длинные запросы**
• короткие запросы - когда количество строк, необходимых для получения результата, невелико независимо от того, насколько велики задействованные таблицы. Короткие запросы могут считывать все строки из маленьких таблиц, но лишь небольшой % строк из больших таблиц
• длинные запросы - если селективность запроса низка по крайней мере для одной из больших таблиц; то есть результат, даже если он невелик,
определяется почти всеми строками
• результат count от большой таблицы — невелик, но задействованы все строки большой таблицы

**Оптимизация коротких запросов**
• определить наиболее ограничительные критерии (по значениям в таблице) и убедиться, что на эти критерии есть индексы
• подумать об испольховании покрывающего индекса для Index Only Scan
• при построении запроса начни писать его с наиболее ограничительной части, добавляя затем к ней соединения
• вместо использования соединений и фильтрации его результатов

**Оптимизация длинных запросов**
• скорее всего это OLAP-запрос, аналитический. Убедись, что он не выполняется часто и много на продакшн базе данных
• можно подумать о материализованном представлении, которое нужно будет вручную (каким-то запросом) обновлять через refresh 
• OLTP-запросы не должны быть длинными!
• подумай о внедрении инкрементальных обновлений
• кешируем результаты в отдельной таблице и добавляем в эту таблицу
новые значения вместо переработки всей таблицы
• убедись, что наиболее ограничительная операция выполняется в плане первой, добейся этого
• добейся того, чтобы большие таблицы читались однократно в плане запроса такие запросы • можно гонять на отдельной БД

**Как найти наиболее медленные запросы?**
подключите расширение pg_stat_statements
```sql
create extension pg_stat_statements;
alter system set shared_preload_libraries = 'pg_stat_statements';
```
(почитайте в документации, где лежит статистика запросов)

**Как поиграть с настройками базы данных для ее ускорения**
•можно увеличить work_mem (например, до 64 MB) и hash_mem_multiplier для увеличения объёма RAM, доступной для операций внутри запроса, в том числе для операций с Hash join
• можно уменьшить random_page_cost для быстрых SSD (с 4 до 1.1, например)
• shared_buffers стоит установить в 30-40% от доступной памяти на сервере
• конечно, используйте пулер коннектов (Pgbouncer, Odyssey)

**Где почитать?**
• Книга «Оптимизация запросов в PostgreSQL», Домбровская Г., Новиков Б., Бейликова А.
Как накатить данные для этой книги из PosgreSQL. Забрать postgres_air.backup по ссылке.
https://drive.google.com/drive/folders/13F7M80Kf_somnjb-mTYAnh1hW1Y_g4kJ?usp=drive_link
В PosgreSQL:
```
-- Предварительно перед восстановленим создаем пользователя hettie на сервере
CREATE USER hettie  
    WITH SUPERUSER CREATEDB CREATEROLE REPLICATION BYPASSRLS  
    PASSWORD 'Gnusmas';
```
В "Переменные среды" в Path (вставить сюда путь до утилит в том числе createdb):
```
C:\Program Files\PostgreSQL\17\bin
```
В Power Shell:
```
createdb --username=hettie test_db_air
createdb --username=postgres test_db_air
cd "c:\program files\postgresql\17\bin"
pg_restore --username=hettie -d test_db_air -v postgres_air.backup
```
![[Оптимизация_запросов_в_postgresql_Г_Домбровская_Б_Новиков_А_Бейликова.pdf]]
• Курс Postgres Professional - https://postgrespro.ru/education/courses/QPT
• Книга «Изучаем PostgreSQL 10», Андрей Волков, Джуба С.
• Книга <<PostgreSQL 16 изнутри», Рогов Егор
# Индексы
Сканирование только индекса позволяет не считывать всю таблицу, но только при условии, что все поля под select есть в самом индексе.
```sql
create index ... include (...); -- включаем доп столбцы, поиск по ним рабоать не будет, но достать их будет можно
```
# VACUUM