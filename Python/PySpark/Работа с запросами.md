Зададим схему файла

```python
# Programmatic way to define a schema 
fire_schema = StructType([StructField('CallNumber', IntegerType(), True),
                     StructField('UnitID', StringType(), True),
                     StructField('IncidentNumber', IntegerType(), True),
                     StructField('CallType', StringType(), True),                  
                     StructField('CallDate', StringType(), True),      
                     StructField('WatchDate', StringType(), True),
                     StructField('CallFinalDisposition', StringType(), True),
                     StructField('AvailableDtTm', StringType(), True),
                     StructField('Address', StringType(), True),       
                     StructField('City', StringType(), True),       
                     StructField('Zipcode', IntegerType(), True),       
                     StructField('Battalion', StringType(), True),                 
                     StructField('StationArea', StringType(), True),       
                     StructField('Box', StringType(), True),       
                     StructField('OriginalPriority', StringType(), True),       
                     StructField('Priority', StringType(), True),       
                     StructField('FinalPriority', IntegerType(), True),       
                     StructField('ALSUnit', BooleanType(), True),       
                     StructField('CallTypeGroup', StringType(), True),
                     StructField('NumAlarms', IntegerType(), True),
                     StructField('UnitType', StringType(), True),
                     StructField('UnitSequenceInCallDispatch', IntegerType(), True),
                     StructField('FirePreventionDistrict', StringType(), True),
                     StructField('SupervisorDistrict', StringType(), True),
                     StructField('Neighborhood', StringType(), True),
                     StructField('Location', StringType(), True),
                     StructField('RowID', StringType(), True),
                     StructField('Delay', FloatType(), True)])
```
### Прочитаем данные в DataFrame
```python
# Use the DataFrameReader interface to read a CSV file
sf_fire_file = "sf-fire-calls.csv"
fire_df = spark.read.csv(sf_fire_file, header=True, schema=fire_schema)

# Cache the DataFrame since we will be performing some operations on it.
fire_df.cache()
fire_df.count()

fire_df.printSchema()
```
### Фильтрация данных
```python
# Note that filter() and where() methods on the DataFrame are similar. Check relevant documentation for their respective argument types.
few_fire_df = (fire_df
               .select("IncidentNumber", "AvailableDtTm", "CallType")
               .where(F.col("CallType") != "Medical Incident"))
few_fire_df.show(1, vertical=True)

# Q-2) What are distinct types of calls were made to the Fire Department?
# These are all the distinct type of call to the SF Fire Department
(fire_df
  .select("CallType")
  .where(
      (F.col("CallType").isNotNull())
     & (F.col("City") == "SF")
  )
  .distinct()
  .count())
# Q-3) Find out all response or delayed times greater than 5 mins?
# Rename the column Delay - > ReponseDelayedinMins
# Returns a new DataFrame
# Find out all calls where the response time to the fire site was delayed for more than 5 mins
# new_fire_df = fire_df.withColumnRenamed("Delay", "ResponseDelayedinMins")
(fire_df
  .withColumn("OnWatchDate", F.col("Delay"))
  .select("Delay")
  .where(F.col("Delay") > 5)
  .count()
)

# Q-4b) What San Francisco neighborhoods are in the zip codes 94102 and 94103
# Let's find out the neighborhoods associated with these two zip codes. In all likelihood, these are some of the contested neighborhood with high reported crimes.
(fire_ts_df
  .select("Neighborhood", "Zipcode")
  .where(F.col("Zipcode").isNotNull())
  .where((F.col("Zipcode")== 94102) | (F.col("Zipcode")== 94103))
  .count()
  # .show(n=10, truncate=False)
)
```
### Агрегация Distinct, agg, groupBy
```python
# return number of distinct types of calls using countDistinct()
from pyspark.sql.functions import *
(fire_df
  .select("CallType")
  .where(F.col("CallType").isNotNull())
  .agg(F.countDistinct("CallType").alias("DistinctCallTypes"))
  .show())

(fire_df
  .select("CallType")
  .where(F.col("CallType").isNotNull())
  .distinct()
  .count())
# what were the most common types of fire calls?
(fire_ts_df
  .select("CallType")
  .where(F.col("CallType").isNotNull())
  .groupBy("CallType")
  .count()
  .orderBy("count", ascending=False)
  .show(n=10, truncate=False))

```
### Переименование колонок в DataFrame
```python
# Rename column
new_fire_df = fire_df.withColumnRenamed("Delay", "ResponseDelayedinMins")
(new_fire_df
  .select("ResponseDelayedinMins")
  .where(F.col("ResponseDelayedinMins") > 5)
  .show(5, False))
```
### Форматирование даты и удаление столбцов
```python
# date operations
fire_ts_df = (new_fire_df
  .withColumn("IncidentDate", F.to_timestamp(F.col("CallDate"), "MM/dd/yyyy"))
  .drop("CallDate") 
  .withColumn("OnWatchDate", F.to_timestamp(F.col("WatchDate"), "MM/dd/yyyy"))
  .drop("WatchDate") 
  .withColumn("AvailableDtTS", F.to_timestamp(F.col("AvailableDtTm"), 
  "MM/dd/yyyy hh:mm:ss a"))
  .drop("AvailableDtTm")
  # .show(5, truncate=False, vertical=True)
             )
# Select the converted columns
(fire_ts_df
  .select("IncidentDate", "OnWatchDate", "AvailableDtTS")
  .show(5, False))
```

### min,max, avg
```python
# min,max, avg
(fire_ts_df
  .select(F.sum("NumAlarms"), F.avg("ResponseDelayedinMins"),
    F.min("ResponseDelayedinMins"), F.max("ResponseDelayedinMins"))
  .show())
```
### Использование чистого SQL
```python
# ** Q-7) What neighborhoods in San Francisco had the worst response time in 2018?**
# It appears that if you living in Presidio Heights, the Fire Dept arrived in less than 3 mins, while Mission Bay took more than 6 mins.
q_7 = (fire_df
 .withColumn("IncidentDate", F.to_timestamp(F.col("CallDate"), "MM/dd/yyyy"))
 .select("City", F.year("IncidentDate"), "Neighborhood", "Delay")
 .where("City = 'San Francisco' AND YEAR(IncidentDate) = 2018")
 .groupBy("City", "Neighborhood")
 # .count()
 # .distinct()
 .agg(F.avg("Delay"))
 .orderBy("avg(Delay)", ascending=False)
 .show(10, truncate=False, vertical=True)
)
```
### Parquet file
Parquet - поколоночное хранение с поддержкой вложенных данных, был создан для Hadoop экосистемы , для аналитических задач. Самый популярный для бигдата формат хранения данных.
```python
# ** Q-8a) How can we use Parquet files or SQL table to store data and read it back?**
q_8 = (fire_df
 .withColumn("IncidentDate", F.to_timestamp(F.col("CallDate"), "MM/dd/yyyy"))
 .select("City", F.year("IncidentDate"), "Neighborhood", "Delay")
 .where("City = 'San Francisco' AND YEAR(IncidentDate) = 2018")
 .groupBy("City", "Neighborhood")
 # .count()
 # .distinct()
 .agg(F.avg("Delay"))
 .orderBy("avg(Delay)", ascending=False)
)

import tempfile
with tempfile.TemporaryDirectory(prefix="parquet") as d:
    # Write a DataFrame into a Parquet file
    q_8.write.parquet(d, mode="overwrite")

# ** Q-8c) How can read data from Parquet file?**
# Note we don't have to specify the schema here since it's stored as part of the Parquet metadata
    # Read the Parquet file as a DataFrame.
    q_8_c = spark.read.format("parquet").load(d)
    q_8_c.show()
```

