предыдущая [[4_1  Из чего состоит Airflow]]
следующая [[4_2 Веб интерфейс]]

#### Executors

Мы уже коснулись того что такое Executors на прошлом шаге, давайте разберемся чуть чуть подробнее. Executors определяют, какие задачи будут запускаться, как они будут параллельно выполняться и какие механизмы контроля и мониторинга используются.

Что это значит? Дело в том что Airflow позволяет решать как развернуть систему, и каким образом запускать задачи, например вы можете реализовать самый простой последовательный запуск задач, или же настроить параллельность.

Существует 2 типа Executors, первый запускает таски локально, то есть на 1 компьютере.

- `Sequential Executor (по умолчанию)` использует sqlite базу данных. Не умеет запускать задачи параллельно, только последовательно.
- `Local Executor` требует для бекенда клиент-серверную базу данных, умеет использовать параллелизм. В самом простом варианте можно поставить вместе с PostgreSQL.

Помимо локальных версий, существует возможность разместить Airflow на нескольких компьютерах. 

- `Celery Executor` (использующий celery) дает возможность скалировать воркеры на несколько машин, то есть реализовать кластер. 
- `Kubernetes Executor` позволяет поднять Airflow в кубер кластере. Что дает очень гибкие возможности масштабирования системы.

**Celery Executor**

Давайте представим простую ситуацию, что мы хотим чтобы наша машина имела масштабируемость, то есть мы могли бы добавлять дополнительные машины на которых бы исполнялись наши задачи. То есть если у нас есть 2 задачи, то каждая может отправиться работать на различные машины. Звучит здорово, однако для реализации такого нам нужен механизм  синхронизации, или очередь. Чтобы мы понимали когда и куда нужно отправить нашу задачу, именно с этим и помогает разобраться `Celery Executor` 

![](https://ucarecdn.com/1f11ac28-e00b-4658-bfd5-5edf34e207b5/)

#### Pools

Pools это механизм ограничения параллелизма задач, если для примера у вас имеется даг с сотнями параллельных задач, то есть риск сильно загрузить ваш сервер, для этого существуют пулы, их можно создать вручную и указать в настройках дага.

Например можно создать пул на 10 потоков, тогда за раз не будет загружаться более 10 задач. По умолчанию этот показатель равен 128.

Пример указания пула в даге. Вручную был создан Pool `Admin -> Pools`

```lisp
aggregate_db_message_job = BashOperator(
    task_id='task_1',
    pool='non_default_pool',
    bash_command="echo 1",
    dag=dag,
)
```

![](https://ucarecdn.com/5dcf0928-2610-42ba-9744-bc8ff118b509/)

Механизм пулов полезен когда мы имеем некоторую редко работающая задачу которая сильно нагружает сервер, тогда чтобы ограничить потребление ресурсов можно создать дополнительный пул с меньшим количеством слотов.

**Пример в облаке**

Для того чтобы увидеть разницу между разными пулами вам следует провести эксперимент с этими двумя дагами [первый](http://158.160.116.58:8001/tree?dag_id=0_Examples_4.1.4.many) и [второй](http://158.160.116.58:8001/tree?dag_id=0_Examples_4.1.4.only_one). По названию очевидно за что каждый из них отвечает. Попробуйте включить каждый их них и посмотреть как быстро отрабатывает первый и медленно второй. Также я рекомендую включить данную плашку чтобы было нагляднее, справа.

![](https://ucarecdn.com/7be9a31b-416d-4703-b3bc-beceaed2d306/)
