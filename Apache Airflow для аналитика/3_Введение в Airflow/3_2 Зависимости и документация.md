предыдущая [[3_2 Аргументы для DAG и Operator]]
следующая [[3_2 Задание на написание зависимостей между задачами]]

**Документация**

Организуем документацию к нашему коду, к каждому DAG и каждому Task. На практике рекомендую всегда прописывать что это за даг и зачем он нужен, когда количество дагов становится больше 100, а над проектом работаете не вы один то без документации крайне и крайне сложно.

```python
from airflow import DAG
from datetime import timedelta
from airflow.utils.dates import days_ago
from airflow.operators.python_operator import PythonOperator

def f_callable():
  print("Hello World!")

dag = DAG('dag',schedule_interval=timedelta(days=1), start_date=days_ago(1))
# Создадим оператор для исполнения python функции
t1 = PythonOperator(task_id='print', python_callable=f_callable,dag=dag)

# Документация
t1.doc_md = "Task Documentations :)"
dag.doc_md = "Dag Documentations :)"
```

Пример того как это будет отображено в веб интерфейсе

![](https://ucarecdn.com/2a660f11-c542-4041-ac2d-2d3d14f6212c/)

Для того чтобы прочитать документацию к задаче, нужно перейти в уже известный нам Task Instance Details

![](https://ucarecdn.com/d305bb92-aa43-4f71-b096-c4c635679ee0/)

**Зависимости**

Как мы уже поняли то между задачами мы можем организовать порядок исполнения, например кто от кого зависит, какие задачи могут и должны выполняться параллельно. Для того чтобы сделать это проще в Airflow были перегружены операторы `>>` и `[]` , которые позволяют компактно организовать зависимость между вашими задачами. Разберемся с зависимости на примере скрипта:

```python
from airflow import DAG
from datetime import timedelta
from airflow.utils.dates import days_ago
from airflow.operators.dummy_operator import DummyOperator
 
# Создадим объект класса DAG
dag =  DAG('dag', schedule_interval=timedelta(days=1), start_date=days_ago(1))

# Создадим несколько шагов, которые будут параллельно исполнять dummy(пустые)команды
t1 = DummyOperator(task_id='task_1', dag=dag)
t2 = DummyOperator(task_id='task_2', dag=dag)
t3 = DummyOperator(task_id='task_3', dag=dag)
t4 = DummyOperator(task_id='task_4', dag=dag)

# Настройка зависимостей
t1 >> [t2, t3] >> t4
```

Последовательное исполнение одной задачи после другой: 

```bash
t1 >> t2 | t2 исполнится только после t1

t1 << t2 | t1 исполнится только после t2
```

Параллельное исполнение нескольких задач:

```csharp
[t2, t3] | Будут запущены параллельно

# Можно вот так
# Аналогично коду выше
t2
t3
```

Параллельно последовательное исполнение задач

```1c
t1 >> [t2, t3] | Исполнение t2, t3 будет только после t1

t1 << [t2, t3] | Исполнение t1 будет только после t2, t3
[t2, t3] >> t1 | Аналогично коду выше
```

Как нельзя настроить исполнение: 

```css
Операция [t1, t2] >> [t3, t4] не определена
```

#### **Материалы для практики**

```javascript
from airflow import DAG
from datetime import timedelta
from airflow.utils.dates import days_ago
from airflow.operators.dummy_operator import DummyOperator
 
dag = DAG('dag',schedule_interval=timedelta(days=1), start_date=days_ago(1))
t1 = DummyOperator(task_id='task_1', dag=dag)
t2 = DummyOperator(task_id='task_2',dag=dag)
t3 = DummyOperator(task_id='task_3',dag=dag)
t4 = DummyOperator(task_id='task_4',dag=dag)


t1.doc_md = "Task Documentations :)"
dag.doc_md = __doc__ 
dag.doc_md = "Dag Documentations :)"
 
t1 >> t2 >> [t3, t4]
```

**Пример в облаке**

Ссылка на DAG: [http://158.160.116.58:8001/tree?dag_id=0_Examples_3.2.8](http://158.160.116.58:8001/tree?dag_id=0_Examples_3.2.8) 

В данном DAG-е посмотрите на документацию DAG, и по данной [ссылке](http://158.160.116.58:8001/task?dag_id=3.2.8&task_id=print&execution_date=2023-12-02T00%3A00%3A00%2B00%3A00) посмотрите документацию Task